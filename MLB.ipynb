{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime \n",
    "import pytz\n",
    "from pathlib import Path\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access token: eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJpc3MiOiJpbmZvQHhpYm9zaWduYWdlLmNvbSIsImF1ZCI6IjFkMzhmNDExYTY5MjgwMThjZmMzYTQxMWIxMjBkMTI0YmY4MWFmNzYiLCJqdGkiOiIxZjQwMzM2ZDdmZjJhZmVhZWFhNWUzMDE0YjdlMTU4ZDBlMjllMWMyOTcwZThjY2E1MzQwODVhNGFiMjJiZGQ5YjUyMTQzMjAyMWFlYjA3YSIsImlhdCI6MTcyMzE3ODIyMywibmJmIjoxNzIzMTc4MjIzLCJleHAiOjE3MjMxODE4MjMsInN1YiI6IjUiLCJzY29wZXMiOlsiYWxsIl19.F7GeWZtAuMrH_sqUM_qUp_YYN_HXvT0fj9sa4ENQVcgaXwmlOdcinXuvRihmWIhh24WpoWBIZLYEDhuLnUsd3B0C6rcRWcbEM11ZIOEm0ULnE1NGZDhOCGYFDcXCU8gTCrAe2n4eyAdknfXSxJBvV0dGEyZkDQBpz7U0G8JpQOivTdSIRh0HGlAnZfXhPlnEGZgWKSKFCW5yJKf-jMSfJ-xPq3F7ncHSLaaKaGfpAWO4RCyXX0myxFPeUeA2GULwsilT_bYBX3NJgoxHx8VJdVUzC84Va_mGrmCD_8erPeghYeV_xvrr8m-ZUkCT2QiSBJIkV6RpRyIqYEAlVkVJIA\n"
     ]
    }
   ],
   "source": [
    "# init cms authentication\n",
    "url = \"https://cdn2.barvanna.com/api/authorize/access_token\"\n",
    "client_id = \"1d38f411a6928018cfc3a411b120d124bf81af76\"\n",
    "client_secret = \"214713e8ab75008865825bb99fe5f3e1b8ecf56b9acbc70c3002df4de4241a11210b6f5983679a15b48842fd6e1e889508f25f3b5b0dc2c83a831b529f4d0c27bfe64e3b9fb47ab1a482aaaf174b0f4a5b63ca00873b810b9d7f360bf6796176043e981b736a46a6921edf78135523b62243bbbd0232b0b5650ae321cdb38a\"\n",
    "grant_type = \"client_credentials\"\n",
    "\n",
    "# Define the payload for the form-data\n",
    "form_data = {\n",
    "    'client_id': client_id,\n",
    "    'client_secret': client_secret,\n",
    "    'grant_type': grant_type\n",
    "}\n",
    "\n",
    "# Make the request\n",
    "response = requests.post(url, data=form_data)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the returned JSON for the access token\n",
    "    token_data = response.json()\n",
    "    access_token = token_data.get('access_token')\n",
    "    print('Access token:', access_token)\n",
    "    headers = {\n",
    "            'Authorization': f'Bearer {access_token}'\n",
    "        }\n",
    "else:\n",
    "    print('Failed to get access token. Status code:', response.status_code, 'Response:', response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items in the array: 10\n"
     ]
    }
   ],
   "source": [
    "#list out all the layout (should be 15) form folder number 7 \n",
    "#if count is 0 fetch all fifteen.\n",
    "\n",
    "layout_list_by_folder= 'https://cdn2.barvanna.com/api/layout?folderId=7'\n",
    "\n",
    "def check_layout_response(url, headers=None):\n",
    "    try:\n",
    "        # Send a GET request to the URL with optional headers\n",
    "        response = requests.get(url, headers=headers)\n",
    "\n",
    "        # Raise an exception if the request was unsuccessful\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # Try to parse the response as JSON\n",
    "        data = response.json()\n",
    "        # Count the number of items in the JSON array\n",
    "        item_count = len(data)\n",
    "\n",
    "        print(\"Number of items in the array:\", item_count)\n",
    "        # Check if data is a list and has 15 elements or is empty\n",
    "        if isinstance(data, list) and (len(data) > 5):\n",
    "        \n",
    "            return True\n",
    "            \n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        # Handle any errors during the request\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return False\n",
    "    except ValueError:\n",
    "        # Handle case where the response is not valid JSON\n",
    "        print(\"The response is not valid JSON.\")\n",
    "        return False\n",
    "    \n",
    "\n",
    "result = check_layout_response(layout_list_by_folder, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_url = 'https://assets.vedia.ai/rawshorts/public/vedia/mrss/prod/generic/sports-previews/mlb-pre/rss/baseball/mlb-game-preview/barvanna/latest.mrss.xml'\n",
    "# source_url = 'https://cdn.itsoch.com/latest.mrss.xml'\n",
    "\n",
    "# URL for uploading the video\n",
    "upload_url = 'https://cdn2.barvanna.com/api/library'\n",
    "layout_url = 'https://cdn2.barvanna.com/api/layout'\n",
    "\n",
    "# Function to download a file with progress\n",
    "def download_file(url, local_filename):\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        total_size = int(r.headers.get('content-length', 0))\n",
    "        with open(local_filename, 'wb') as f, tqdm(\n",
    "            desc=local_filename,\n",
    "            total=total_size,\n",
    "            unit='iB',\n",
    "            unit_scale=True,\n",
    "        ) as bar:\n",
    "            for chunk in r.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "                bar.update(len(chunk))\n",
    "\n",
    "# Function to upload a file with progress\n",
    "def upload_file(file_path, url, data, headers):\n",
    "    total_size = int(file_path.stat().st_size)\n",
    "    with open(file_path, 'rb') as f, tqdm(\n",
    "        desc=f'Uploading {file_path.name}',\n",
    "        total=total_size,\n",
    "        unit='iB',\n",
    "        unit_scale=True\n",
    "    ) as bar:\n",
    "        class UploadProgress:\n",
    "            def __init__(self, file, bar):\n",
    "                self.file = file\n",
    "                self.bar = bar\n",
    "\n",
    "            def read(self, size=-1):\n",
    "                data = self.file.read(size)\n",
    "                self.bar.update(len(data))\n",
    "                return data\n",
    "\n",
    "        files = {'files': (file_path.name, UploadProgress(f, bar), 'video/mp4')}\n",
    "        response = requests.post(url, files=files, data=data, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constants\n",
    "teams_videos = []\n",
    "formatted_date = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_source() :\n",
    "    # Fetch the XML content from the URL\n",
    "    response = requests.get(source_url)\n",
    "    response.raise_for_status()\n",
    "    xml_content = response.content\n",
    "\n",
    "    # Parse the XML content\n",
    "    root = ET.fromstring(xml_content)\n",
    "\n",
    "    # Define the namespace\n",
    "    namespaces = {'media': 'http://search.yahoo.com/mrss/'}\n",
    "\n",
    "    # Iterate through each item in the feed\n",
    "    for item in root.findall('.//item'):\n",
    "        media_group = item.find('media:group', namespaces)\n",
    "        custom_parms = item.find('customParams', namespaces)\n",
    "        if custom_parms is not None:\n",
    "            expire_date = custom_parms.find('match_date', namespaces)\n",
    "            if expire_date is not None:\n",
    "                expire_date_text = expire_date.text.strip()\n",
    "                # Define the format of the input date string\n",
    "                input_format = \"%B %d, %Y %H:%M\"\n",
    "\n",
    "                # Parse the date string into a naive datetime object\n",
    "                naive_datetime_obj = datetime.strptime(expire_date_text, input_format)\n",
    "\n",
    "                # Assume the input datetime is in a specific timezone (e.g., 'US/Eastern')\n",
    "                # Replace 'US/Eastern' with the desired timezone\n",
    "                timezone_obj = pytz.timezone('US/Eastern')\n",
    "\n",
    "                # Localize the naive datetime object to the specific timezone\n",
    "                localized_datetime_obj = timezone_obj.localize(naive_datetime_obj)\n",
    "\n",
    "                # Define the output format\n",
    "                output_format = \"%Y-%m-%d %H:%M:%S %Z\"\n",
    "\n",
    "                # Convert the localized datetime object to the desired format\n",
    "                formatted_date = localized_datetime_obj.strftime(output_format)\n",
    "\n",
    "                # print(formatted_date)\n",
    "\n",
    "        if media_group is not None:\n",
    "            teams = media_group.find('media:team', namespaces)\n",
    "            video_content = media_group.find('media:content[@type=\"video/mp4\"]', namespaces)\n",
    "            if teams is not None and video_content is not None:\n",
    "                teams_text = teams.text.strip()\n",
    "                video_url = video_content.get('url')\n",
    "                # Append the team and video URL to the array\n",
    "                teams_videos.append({'teams': teams_text, 'video_url': video_url})\n",
    "\n",
    "    # Print the array\n",
    "    print(teams_videos)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_layout():\n",
    "    # Loop through each item in teams_videos and upload the video\n",
    "    for item in teams_videos:\n",
    "        try:\n",
    "            teams_text = item['teams'].replace(' ', '_')\n",
    "            video_url = item['video_url']\n",
    "\n",
    "            # Step 1: Download the video file from the provided URL\n",
    "            filename = f\"{video_url.split('/')[-1].split('.')[0]}.mp4\"\n",
    "            download_file(video_url, filename)\n",
    "\n",
    "            # Step 2: Upload the video file via POST request\n",
    "            file_path = Path(filename)\n",
    "            data = {\n",
    "                'name': filename,\n",
    "                'folderId': '5',\n",
    "                'deleteOnExpiry': 1,\n",
    "                # 'expires' : '2024-09-08 21:20:00'\n",
    "                'expires': formatted_date\n",
    "            }\n",
    "            headers = {\n",
    "                'Authorization': f'Bearer {access_token}'\n",
    "            }\n",
    "\n",
    "            # Perform the upload\n",
    "            upload_response = upload_file(file_path, upload_url, data, headers)\n",
    "            uploaded_media_id = upload_response.json()['files'][0]['mediaId']\n",
    "            print(f\"Uploaded {filename}: {upload_response.text}\")\n",
    "\n",
    "            # Step 3: Create a new layout for the video\n",
    "            layout_data = {\n",
    "                'resolutionId': 1,\n",
    "                'name': teams_text,\n",
    "                'folderId': '7'\n",
    "            }\n",
    "            layout_headers = {\n",
    "                'Authorization': f'Bearer {access_token}',\n",
    "                'Content-Type': 'application/json'\n",
    "            }\n",
    "            layout_response = requests.post(layout_url, json=layout_data, headers=layout_headers)\n",
    "            layout_response.raise_for_status()\n",
    "            original_layout_id = layout_response.json()['layoutId']\n",
    "            print(f\"Created layout for {teams_text}: {layout_response.text}\")\n",
    "\n",
    "            # Get the draft layout ID\n",
    "            draftid_url = f\"https://cdn2.barvanna.com/api/layout?parentId={original_layout_id}\"\n",
    "            draft_response = requests.get(draftid_url, headers=layout_headers)\n",
    "            draft_response.raise_for_status()\n",
    "            draft_layout_id = draft_response.json()[0]['layoutId']\n",
    "            print(f\"Draft layout ID: {draft_layout_id}\")\n",
    "\n",
    "            # Get the playlist ID of the draft layout\n",
    "            draft_layout_details_url = f\"https://cdn2.barvanna.com/api/layout?layoutId={draft_layout_id}&embed=regions,playlists,widgets\"\n",
    "            draft_layout_response = requests.get(draft_layout_details_url, headers=layout_headers)\n",
    "            draft_layout_response.raise_for_status()\n",
    "            playlist_id = draft_layout_response.json()[0]['regions'][0]['regionPlaylist']['playlistId']\n",
    "            print(f\"Playlist ID: {playlist_id}\")\n",
    "\n",
    "            # Step 4: Assign the uploaded media to the playlist\n",
    "            assign_url = f'https://cdn2.barvanna.com/api/playlist/library/assign/{playlist_id}'\n",
    "            payload = {'media': [uploaded_media_id]}  # Ensure the media is sent as an array\n",
    "            assign_response = requests.post(assign_url, json=payload, headers=layout_headers)\n",
    "            assign_response.raise_for_status()\n",
    "            print(f\"Assigned media ID {uploaded_media_id} to playlist ID {playlist_id}\")\n",
    "\n",
    "            # Step 5: Publish the layout\n",
    "            publish_url = f'https://cdn2.barvanna.com/api/layout/publish/{original_layout_id}'\n",
    "            publishref = {'publishNow': 1}\n",
    "            publish_response = requests.put(publish_url, json=publishref, headers=layout_headers)\n",
    "            publish_response.raise_for_status()\n",
    "            published_layout_id = publish_response.json()['layoutId']\n",
    "            print(f\"Published layout ID: {published_layout_id}\")\n",
    "\n",
    "            # Step 6: Insert the published layout into the campaign\n",
    "            # campaign_url = 'https://cdn2.barvanna.com/api/campaign/layout/assign/2248'\n",
    "            # campaign_payload = {'layoutId': published_layout_id}\n",
    "            # campaign_response = requests.post(campaign_url, json=campaign_payload, headers=layout_headers)\n",
    "            # campaign_response.raise_for_status()\n",
    "            # print(f\"Inserted layout ID {published_layout_id} into campaign\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {item}: {e}\")\n",
    "\n",
    "    print(\"Completed processing all items\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response met the expected criteria of 15 layout in the folder\n"
     ]
    }
   ],
   "source": [
    "#check if the MLB folder is empty and dont have 15 matches , now grab the matches and create the layout one by one if the result dont have 15 matches\n",
    "\n",
    "if not result:\n",
    "    # Code to execute if result is False\n",
    "    print(\"The response did not meet the expected criteria. Executing code to download and setup all 15 layout\")\n",
    "    # Insert your alternate block of code here\n",
    "    fetch_source()\n",
    "    create_layout()   \n",
    "    \n",
    "else:\n",
    "    print(\"The response met the expected criteria of 15 layout in the folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_names = teams_videos\n",
    "cms_layout = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'layout': 'ATHLETICS_,_ANGELS', 'layoutId': 11316}, {'layout': 'BRAVES_,_METS', 'layoutId': 11314}, {'layout': 'CUBS_,_ROYALS', 'layoutId': 11261}, {'layout': 'DODGERS_,_ASTROS', 'layoutId': 11259}, {'layout': 'GUARDIANS_,_PHILLIES', 'layoutId': 11275}, {'layout': 'MARINERS_,_WHITE_SOX', 'layoutId': 11265}, {'layout': 'MARLINS_,_BREWERS', 'layoutId': 11255}, {'layout': 'NATIONALS_,_CARDINALS', 'layoutId': 11257}, {'layout': 'PADRES_,_ORIOLES', 'layoutId': 11279}, {'layout': 'PIRATES_,_DIAMONDBACKS', 'layoutId': 11285}, {'layout': 'RANGERS_,_BLUE_JAYS', 'layoutId': 11271}, {'layout': 'REDS_,_RAYS', 'layoutId': 11277}, {'layout': 'ROCKIES_,_GIANTS', 'layoutId': 11253}, {'layout': 'TWINS_,_TIGERS', 'layoutId': 11273}, {'layout': 'YANKEES_,_RED_SOX', 'layoutId': 11263}]\n"
     ]
    }
   ],
   "source": [
    "#now check and compare the layout name and source names.\n",
    "#lets fetch source and fetch layout name from the cms folder and make an array and compare the both names respectively.\n",
    "#the araay comparison may be up and down , but what we do is , we dont touch existing names and we replace new name from source to unmatch layout in cms.\n",
    "\n",
    "def fetch_and_merge_layouts(url1, url2, headers):\n",
    "    \"\"\"\n",
    "    Fetch JSON data from two URLs with headers, merge them, and extract 'layout' names and 'layoutId's into an array.\n",
    "    \n",
    "    Parameters:\n",
    "    url1 (str): The first URL to fetch JSON data from.\n",
    "    url2 (str): The second URL to fetch JSON data from.\n",
    "    headers (dict): Headers to include in the HTTP requests.\n",
    "    \n",
    "    Returns:\n",
    "    list: An array of dictionaries containing 'layout' names and 'layoutId's from the merged JSON data.\n",
    "    \"\"\"\n",
    "    # Fetch JSON data from both URLs with headers\n",
    "    response1 = requests.get(url1, headers=headers)\n",
    "    response2 = requests.get(url2, headers=headers)\n",
    "\n",
    "    # Parse the JSON data\n",
    "    json_data1 = response1.json()\n",
    "    json_data2 = response2.json()\n",
    "\n",
    "    # Merge the two JSON arrays\n",
    "    merged_data = json_data1 + json_data2\n",
    "\n",
    "    # Extract 'layout' names and 'layoutId's into a list of dictionaries\n",
    "    layout_details = [{'layout': item['layout'], 'layoutId': item.get('layoutId')} for item in merged_data]\n",
    "\n",
    "    return layout_details\n",
    "\n",
    "# Example usage\n",
    "url1 = 'https://cdn2.barvanna.com/api/layout?folderId=7&start=0&size=10'\n",
    "url2 = 'https://cdn2.barvanna.com/api/layout?folderId=7&start=10&size=15'\n",
    "\n",
    "# Assuming headers is already defined in your environment\n",
    "cms_layout = fetch_and_merge_layouts(url1, url2, headers)\n",
    "print(cms_layout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'teams': 'PIRATES , DIAMONDBACKS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/07/1a/25/7d/071a257dc936ad2b0fd7cdaa68ebc718.preview.mp4'}, {'teams': 'ROCKIES , GIANTS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/c7/c0/fd/88/c7c0fd884b50bf029d0ac194345f20da.preview.mp4'}, {'teams': 'MARLINS , BREWERS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/7a/95/a6/68/7a95a668e667126b19f1e1d6d6e243dd.preview.mp4'}, {'teams': 'NATIONALS , CARDINALS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/a3/53/6d/61/a3536d614e090ea5481fdb80ebd505c9.preview.mp4'}, {'teams': 'DODGERS , ASTROS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/d4/33/8a/5b/d4338a5b2996cdba02128f493662709d.preview.mp4'}, {'teams': 'CUBS , ROYALS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/8f/d1/ed/71/8fd1ed71dbc5b5a9788684c75b29fa3d.preview.mp4'}, {'teams': 'YANKEES , RED SOX', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/f1/0e/e4/93/f10ee493dcaf6eee96f3503286f094c4.preview.mp4'}, {'teams': 'MARINERS , WHITE SOX', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/3f/6f/fd/18/3f6ffd18d02907f0bbe2f105040bcf6d.preview.mp4'}, {'teams': 'BRAVES , METS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/2c/c5/e4/89/2cc5e4893630ff7805d88b0770875c2c.preview.mp4'}, {'teams': 'ATHLETICS , ANGELS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/bc/97/a6/79/bc97a679ae98e4b73a9653b3a88619eb.preview.mp4'}, {'teams': 'RANGERS , BLUE JAYS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/d7/fb/6a/ac/d7fb6aac046f5bf792a8569f1224635d.preview.mp4'}, {'teams': 'TWINS , TIGERS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/6d/f8/f0/50/6df8f05038f35abad2e9994a0e466ea1.preview.mp4'}, {'teams': 'GUARDIANS , PHILLIES', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/b7/4a/93/36/b74a933667e008d26c79471ca76bf9f7.preview.mp4'}, {'teams': 'REDS , RAYS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/da/43/da/9e/da43da9ec08f293b2e090f4a093f3b2a.preview.mp4'}, {'teams': 'PADRES , ORIOLES', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/19/e9/e5/84/19e9e58452df5ed0d469afa5ae02c7fc.preview.mp4'}]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "fetch_source()\n",
    "missing_layouts = []\n",
    "missing_teams = []\n",
    "\n",
    "def compare_arrays(source, cms):\n",
    "    \"\"\"\n",
    "    Compares source and cms arrays, returning two lists:\n",
    "        1. Missing layouts (present in cms but not in source), with layout ID.\n",
    "        2. Missing teams (present in source but not in cms), with team name and video URL.\n",
    "    \"\"\"\n",
    "    source_dict = {tuple(item['teams'].split(' , ')): item for item in source}\n",
    "    cms_dict = {tuple(item['layout'].replace('_', ' ').split(' , ')): item for item in cms}\n",
    "\n",
    "   \n",
    "    for layout, item in cms_dict.items():\n",
    "        if layout not in source_dict:\n",
    "            missing_layouts.append({'layout': item['layout'], 'layoutId': item['layoutId']})\n",
    "\n",
    "    \n",
    "    for team, item in source_dict.items():\n",
    "        if team not in cms_dict:\n",
    "            missing_teams.append({'teams': item['teams'], 'video_url': item['video_url']})\n",
    "\n",
    "# Find the missing layouts\n",
    "update_result = compare_arrays(source_names, cms_layout)\n",
    "\n",
    "def create_replacement_array(missing_layouts, missing_teams):\n",
    "    \"\"\"Creates a replacement array based on missing layouts and teams.\"\"\"\n",
    "    replacements = []\n",
    "    max_length = max(len(missing_layouts), len(missing_teams))\n",
    "\n",
    "    for i in range(max_length):\n",
    "        layout_data = missing_layouts[i] if i < len(missing_layouts) else {'layout': None, 'layoutId': None}\n",
    "        team_data = missing_teams[i] if i < len(missing_teams) else {'teams': None, 'video_url': None}\n",
    "        \n",
    "        # Only create a replacement if either layout or team data is not None\n",
    "        if layout_data['layout'] or team_data['teams']:\n",
    "            replacements.append({\n",
    "                'replace_layout': layout_data['layout'],\n",
    "                'layout_id': layout_data['layoutId'],\n",
    "                'by_team': team_data['teams'],\n",
    "                'video_url': team_data['video_url']\n",
    "            })\n",
    "\n",
    "    return replacements\n",
    "\n",
    "\n",
    "\n",
    "replacement_array = create_replacement_array(missing_layouts, missing_teams)\n",
    "print(replacement_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed processing all items\n"
     ]
    }
   ],
   "source": [
    "#create a function to delete the layout that is in the cms using update_result\n",
    "\n",
    "def delete_and_create_new_layout(arr):\n",
    "    # Loop through each item in teams_videos and upload the video\n",
    "    for item in arr:\n",
    "        try:\n",
    "            layout_headers = {\n",
    "                'Authorization': f'Bearer {access_token}',\n",
    "                'Content-Type': 'application/json'\n",
    "            }\n",
    "\n",
    "            teams_text = item['by_team'].replace(' ', '_')\n",
    "            video_url = item['video_url']\n",
    "            layoutid = 0\n",
    "             \n",
    "            #editing the layout name \n",
    "            if item['layout_id'] is not None:\n",
    "               layoutid = item['layout_id']\n",
    "               edit_url = f\"https://cdn2.barvanna.com/api/layout/{layoutid}\"\n",
    "                # Define the data payload with the parameters you want to update\n",
    "               data_payload = {\n",
    "                        \"name\": teams_text  # Assuming 'name' is part of the item dictionary\n",
    "                    }\n",
    "               edit_response = requests.put(edit_url, headers=layout_headers , json=data_payload)\n",
    "               print(edit_response)\n",
    "\n",
    "            # Step 1: Download the video file from the provided URL\n",
    "            filename = f\"{video_url.split('/')[-1].split('.')[0]}.mp4\"\n",
    "            download_file(video_url, filename)\n",
    "\n",
    "            # Step 2: Upload the video file via POST request\n",
    "            file_path = Path(filename)\n",
    "            data = {\n",
    "                'name': filename,\n",
    "                'folderId': '5',\n",
    "                'deleteOnExpiry': 1,\n",
    "                # 'expires' : '2024-09-08 21:20:00'\n",
    "                'expires': formatted_date\n",
    "            }\n",
    "            headers = {\n",
    "                'Authorization': f'Bearer {access_token}'\n",
    "            }\n",
    "\n",
    "            # Perform the upload\n",
    "            upload_response = upload_file(file_path, upload_url, data, headers)\n",
    "            uploaded_media_id = upload_response.json()['files'][0]['mediaId']\n",
    "            print(f\"Uploaded {filename}: {upload_response.text}\")\n",
    "\n",
    "            #do checkout and get draft id\n",
    "            # # Get the draft layout ID\n",
    "            draftid_url = f\"https://cdn2.barvanna.com/api/layout/checkout/{layoutid}\"\n",
    "            layoutid_payload = {\n",
    "                    \"layoutId\": layoutid,\n",
    "                }\n",
    "            draft_response = requests.put(draftid_url, headers=layout_headers , json=layoutid_payload)\n",
    "            draft_response.raise_for_status()\n",
    "            draft_layout_id = draft_response.json()['layoutId']\n",
    "            print(f\"Draft layout ID: {draft_layout_id}\")\n",
    "\n",
    "            #now get the playlist name , delete the existing video and put another one , ok !\n",
    "            # Get the playlist ID of the draft layout\n",
    "            draft_layout_details_url = f\"https://cdn2.barvanna.com/api/layout?layoutId={draft_layout_id}&embed=regions,playlists,widgets\"\n",
    "            draft_layout_response = requests.get(draft_layout_details_url, headers=layout_headers)\n",
    "            draft_layout_response.raise_for_status()\n",
    "            print(draft_layout_response.json())\n",
    "            playlist_id = draft_layout_response.json()[0]['regions'][0]['regionPlaylist']['playlistId']\n",
    "            print(f\"Playlist ID: {playlist_id}\")\n",
    "\n",
    "            #get old widget id (old video) and delete it from playlist\n",
    "            old_video_widget_id = draft_layout_response.json()[0]['regions'][0]['regionPlaylist']['widgets'][0]['widgetId']\n",
    "            #delete a widget\n",
    "            delete_widget_url = f'https://cdn2.barvanna.com/api/playlist/widget/{old_video_widget_id}'\n",
    "            delete_widget_response = requests.delete(delete_widget_url , headers=layout_headers)\n",
    "            delete_widget_response.raise_for_status()\n",
    "            print(f\"widget deleted :  {old_video_widget_id}\")\n",
    "\n",
    "\n",
    "            # Step 4: Assign the uploaded media to the playlist\n",
    "            assign_url = f'https://cdn2.barvanna.com/api/playlist/library/assign/{playlist_id}'\n",
    "            payload = {'media': [uploaded_media_id]}  # Ensure the media is sent as an array\n",
    "            assign_response = requests.post(assign_url, json=payload, headers=layout_headers)\n",
    "            assign_response.raise_for_status()\n",
    "            print(f\"Assigned media ID 4761 to playlist ID {playlist_id}\")\n",
    "\n",
    "            # Step 5: Publish the layout\n",
    "            publish_url = f'https://cdn2.barvanna.com/api/layout/publish/{layoutid}'\n",
    "            publishref = {'publishNow': 1}\n",
    "            publish_response = requests.put(publish_url, json=publishref, headers=layout_headers)\n",
    "            publish_response.raise_for_status()\n",
    "            published_layout_id = publish_response.json()['layoutId']\n",
    "            print(f\"Published layout ID: {published_layout_id}\")\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {item}: {e}\")\n",
    "\n",
    "    print(\"Completed processing all items\")\n",
    "\n",
    "delete_and_create_new_layout(replacement_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to output_array.json\n",
      "Loaded Data: [{'teams': 'PIRATES , DIAMONDBACKS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/07/1a/25/7d/071a257dc936ad2b0fd7cdaa68ebc718.preview.mp4'}, {'teams': 'ROCKIES , GIANTS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/c7/c0/fd/88/c7c0fd884b50bf029d0ac194345f20da.preview.mp4'}, {'teams': 'MARLINS , BREWERS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/7a/95/a6/68/7a95a668e667126b19f1e1d6d6e243dd.preview.mp4'}, {'teams': 'NATIONALS , CARDINALS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/a3/53/6d/61/a3536d614e090ea5481fdb80ebd505c9.preview.mp4'}, {'teams': 'DODGERS , ASTROS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/d4/33/8a/5b/d4338a5b2996cdba02128f493662709d.preview.mp4'}, {'teams': 'CUBS , ROYALS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/8f/d1/ed/71/8fd1ed71dbc5b5a9788684c75b29fa3d.preview.mp4'}, {'teams': 'YANKEES , RED SOX', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/f1/0e/e4/93/f10ee493dcaf6eee96f3503286f094c4.preview.mp4'}, {'teams': 'MARINERS , WHITE SOX', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/3f/6f/fd/18/3f6ffd18d02907f0bbe2f105040bcf6d.preview.mp4'}, {'teams': 'BRAVES , METS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/2c/c5/e4/89/2cc5e4893630ff7805d88b0770875c2c.preview.mp4'}, {'teams': 'ATHLETICS , ANGELS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/bc/97/a6/79/bc97a679ae98e4b73a9653b3a88619eb.preview.mp4'}, {'teams': 'RANGERS , BLUE JAYS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/d7/fb/6a/ac/d7fb6aac046f5bf792a8569f1224635d.preview.mp4'}, {'teams': 'TWINS , TIGERS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/6d/f8/f0/50/6df8f05038f35abad2e9994a0e466ea1.preview.mp4'}, {'teams': 'GUARDIANS , PHILLIES', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/b7/4a/93/36/b74a933667e008d26c79471ca76bf9f7.preview.mp4'}, {'teams': 'REDS , RAYS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/da/43/da/9e/da43da9ec08f293b2e090f4a093f3b2a.preview.mp4'}, {'teams': 'PADRES , ORIOLES', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/19/e9/e5/84/19e9e58452df5ed0d469afa5ae02c7fc.preview.mp4'}]\n",
      "cms layout [{'layout': 'ATHLETICS_,_ANGELS', 'layoutId': 11316}, {'layout': 'BRAVES_,_METS', 'layoutId': 11314}, {'layout': 'CUBS_,_ROYALS', 'layoutId': 11261}, {'layout': 'DODGERS_,_ASTROS', 'layoutId': 11259}, {'layout': 'GUARDIANS_,_PHILLIES', 'layoutId': 11275}, {'layout': 'MARINERS_,_WHITE_SOX', 'layoutId': 11265}, {'layout': 'MARLINS_,_BREWERS', 'layoutId': 11255}, {'layout': 'NATIONALS_,_CARDINALS', 'layoutId': 11257}, {'layout': 'PADRES_,_ORIOLES', 'layoutId': 11279}, {'layout': 'PIRATES_,_DIAMONDBACKS', 'layoutId': 11285}, {'layout': 'RANGERS_,_BLUE_JAYS', 'layoutId': 11271}, {'layout': 'REDS_,_RAYS', 'layoutId': 11277}, {'layout': 'ROCKIES_,_GIANTS', 'layoutId': 11253}, {'layout': 'TWINS_,_TIGERS', 'layoutId': 11273}, {'layout': 'YANKEES_,_RED_SOX', 'layoutId': 11263}]\n",
      "[]\n",
      "No changes.\n"
     ]
    }
   ],
   "source": [
    "# download the mrss feed into a file\n",
    "# match the old file with new file , only check similar title video name\n",
    "# if video is changed , create a array , put layout id to delete and match name and video name . \n",
    "# if video is changed then delete the old file and save latest mrss as mrss old.\n",
    "\n",
    "#downloading the mrss feed and saving it in the local storage\n",
    "# Define the file path\n",
    "file_path = 'output_array.json'\n",
    "\n",
    "# Save the array to a JSON file\n",
    "# Save the array to a JSON file only if the file doesn't exist\n",
    "if not os.path.exists(file_path):\n",
    "    with open(file_path, 'w') as json_file:\n",
    "        json.dump(teams_videos, json_file, indent=4)\n",
    "    print(f\"Data saved to {file_path}\")\n",
    "else:\n",
    "    print(f\"File {file_path} already exists. No data was saved.\")\n",
    "\n",
    "# Load the array from a JSON file\n",
    "def load_from_json(path):\n",
    "    with open(path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "    return data\n",
    "\n",
    "# Load the array from the file later\n",
    "loaded_data = load_from_json(file_path)\n",
    "print(\"Loaded Data:\", loaded_data)\n",
    "\n",
    "print(\"cms layout\" , cms_layout)\n",
    "\n",
    "# compare loaded data with source data array\n",
    "# Initialize an empty list for new videos\n",
    "new_video = []\n",
    "\n",
    "# Iterate through the output array\n",
    "for out_item in loaded_data:\n",
    "    for src_item in teams_videos:\n",
    "        if out_item['teams'] == src_item['teams'] and out_item['video_url'] != src_item['video_url']:\n",
    "            new_video.append({'teams': out_item['teams'], 'video_url': src_item['video_url']})\n",
    "\n",
    "print (new_video)\n",
    "new_update_array = []\n",
    "\n",
    "\n",
    "# Check if new_video is empty or not and print the appropriate message\n",
    "if not new_video:\n",
    "    print(\"No changes.\")\n",
    "else:\n",
    "    print(\"There is a new video in the existing layout, updating the layout.\")\n",
    "    # compare new video with cms layout and delete the cms layout and replace by new video and name\n",
    "    # Initialize the new array\n",
    "\n",
    "    # Iterate over the new update array\n",
    "    for update in new_video:\n",
    "        teams = update['teams'].replace(' ', '_')  # Format to match layout in CMS\n",
    "        for item in cms_layout:\n",
    "            if item['layout'] == teams:\n",
    "                new_entry = {\n",
    "                    'layout_id': item['layoutId'],\n",
    "                    'by_team': update['teams'],\n",
    "                    'video_url': update['video_url']\n",
    "                }\n",
    "                new_update_array.append(new_entry)\n",
    "    \n",
    "    print(\"new data : \" , new_update_array)\n",
    "     #delete layout id , and put new layout (replacing the layout simplified)\n",
    "    delete_and_create_new_layout(new_update_array)\n",
    "    #delete existing output_array and replace it with current source\n",
    "    # Save the array to a JSON file, replacing it if it already exists\n",
    "    with open(file_path, 'w') as json_file:\n",
    "        json.dump(teams_videos, json_file, indent=4)\n",
    "        print(f\"Data saved to {file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
