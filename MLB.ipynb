{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime \n",
    "import pytz\n",
    "from pathlib import Path\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access token: eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJpc3MiOiJpbmZvQHhpYm9zaWduYWdlLmNvbSIsImF1ZCI6IjFkMzhmNDExYTY5MjgwMThjZmMzYTQxMWIxMjBkMTI0YmY4MWFmNzYiLCJqdGkiOiI4MzM3NzY4MjRhYWEyNDRkMjI4YzA0MjZlNDIxMGE3MTRhODY4OGVhNTZkNjE4YWM4ZjhhZDMyMWIxZWZlNjc5ODcwNWM4YWJmMTQ2MThmNyIsImlhdCI6MTcyMzE3NjQzNSwibmJmIjoxNzIzMTc2NDM1LCJleHAiOjE3MjMxODAwMzUsInN1YiI6IjUiLCJzY29wZXMiOlsiYWxsIl19.IZdL8DWJ4phtWqPZM3iPsvgK4_hFCjaIk1vdNI5GTGst4F08FhRCJkRLp2RiJVxT21WuAjBW9Djvp-TdoCbX34fU88LLaairAorZ_xiq1flyxc5FMiU5v77W5PaTFBZww3QQfQXOynHAP-YmYMNV0Ka9iTfx_6KiuvD55hJdLMWWDh_YimtfTReJKdueF1au613jClTsaocagEq1aN8BmRGymHF7eSS6wLcN1vXJfab7e2m2Coi-Qb4GD-Yo_ZvUmvP1YBG1iwyNzvr84JFRRa966WmYf1oDFPr6vYLlSo506q1tS8tPkwnAiTETlE5ZwsLWS_uGGVY69VUfb3InbQ\n"
     ]
    }
   ],
   "source": [
    "# init cms authentication\n",
    "url = \"https://cdn2.barvanna.com/api/authorize/access_token\"\n",
    "client_id = \"1d38f411a6928018cfc3a411b120d124bf81af76\"\n",
    "client_secret = \"214713e8ab75008865825bb99fe5f3e1b8ecf56b9acbc70c3002df4de4241a11210b6f5983679a15b48842fd6e1e889508f25f3b5b0dc2c83a831b529f4d0c27bfe64e3b9fb47ab1a482aaaf174b0f4a5b63ca00873b810b9d7f360bf6796176043e981b736a46a6921edf78135523b62243bbbd0232b0b5650ae321cdb38a\"\n",
    "grant_type = \"client_credentials\"\n",
    "\n",
    "# Define the payload for the form-data\n",
    "form_data = {\n",
    "    'client_id': client_id,\n",
    "    'client_secret': client_secret,\n",
    "    'grant_type': grant_type\n",
    "}\n",
    "\n",
    "# Make the request\n",
    "response = requests.post(url, data=form_data)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the returned JSON for the access token\n",
    "    token_data = response.json()\n",
    "    access_token = token_data.get('access_token')\n",
    "    print('Access token:', access_token)\n",
    "    headers = {\n",
    "            'Authorization': f'Bearer {access_token}'\n",
    "        }\n",
    "else:\n",
    "    print('Failed to get access token. Status code:', response.status_code, 'Response:', response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items in the array: 10\n"
     ]
    }
   ],
   "source": [
    "#list out all the layout (should be 15) form folder number 7 \n",
    "#if count is 0 fetch all fifteen.\n",
    "\n",
    "layout_list_by_folder= 'https://cdn2.barvanna.com/api/layout?folderId=7'\n",
    "\n",
    "def check_layout_response(url, headers=None):\n",
    "    try:\n",
    "        # Send a GET request to the URL with optional headers\n",
    "        response = requests.get(url, headers=headers)\n",
    "\n",
    "        # Raise an exception if the request was unsuccessful\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # Try to parse the response as JSON\n",
    "        data = response.json()\n",
    "        # Count the number of items in the JSON array\n",
    "        item_count = len(data)\n",
    "\n",
    "        print(\"Number of items in the array:\", item_count)\n",
    "        # Check if data is a list and has 15 elements or is empty\n",
    "        if isinstance(data, list) and (len(data) > 5):\n",
    "        \n",
    "            return True\n",
    "            \n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        # Handle any errors during the request\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return False\n",
    "    except ValueError:\n",
    "        # Handle case where the response is not valid JSON\n",
    "        print(\"The response is not valid JSON.\")\n",
    "        return False\n",
    "    \n",
    "\n",
    "result = check_layout_response(layout_list_by_folder, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_url = 'https://assets.vedia.ai/rawshorts/public/vedia/mrss/prod/generic/sports-previews/mlb-pre/rss/baseball/mlb-game-preview/barvanna/latest.mrss.xml'\n",
    "# source_url = 'https://cdn.itsoch.com/latest.mrss.xml'\n",
    "\n",
    "# URL for uploading the video\n",
    "upload_url = 'https://cdn2.barvanna.com/api/library'\n",
    "layout_url = 'https://cdn2.barvanna.com/api/layout'\n",
    "\n",
    "# Function to download a file with progress\n",
    "def download_file(url, local_filename):\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        total_size = int(r.headers.get('content-length', 0))\n",
    "        with open(local_filename, 'wb') as f, tqdm(\n",
    "            desc=local_filename,\n",
    "            total=total_size,\n",
    "            unit='iB',\n",
    "            unit_scale=True,\n",
    "        ) as bar:\n",
    "            for chunk in r.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "                bar.update(len(chunk))\n",
    "\n",
    "# Function to upload a file with progress\n",
    "def upload_file(file_path, url, data, headers):\n",
    "    total_size = int(file_path.stat().st_size)\n",
    "    with open(file_path, 'rb') as f, tqdm(\n",
    "        desc=f'Uploading {file_path.name}',\n",
    "        total=total_size,\n",
    "        unit='iB',\n",
    "        unit_scale=True\n",
    "    ) as bar:\n",
    "        class UploadProgress:\n",
    "            def __init__(self, file, bar):\n",
    "                self.file = file\n",
    "                self.bar = bar\n",
    "\n",
    "            def read(self, size=-1):\n",
    "                data = self.file.read(size)\n",
    "                self.bar.update(len(data))\n",
    "                return data\n",
    "\n",
    "        files = {'files': (file_path.name, UploadProgress(f, bar), 'video/mp4')}\n",
    "        response = requests.post(url, files=files, data=data, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constants\n",
    "teams_videos = []\n",
    "formatted_date = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_source() :\n",
    "    # Fetch the XML content from the URL\n",
    "    response = requests.get(source_url)\n",
    "    response.raise_for_status()\n",
    "    xml_content = response.content\n",
    "\n",
    "    # Parse the XML content\n",
    "    root = ET.fromstring(xml_content)\n",
    "\n",
    "    # Define the namespace\n",
    "    namespaces = {'media': 'http://search.yahoo.com/mrss/'}\n",
    "\n",
    "    # Iterate through each item in the feed\n",
    "    for item in root.findall('.//item'):\n",
    "        media_group = item.find('media:group', namespaces)\n",
    "        custom_parms = item.find('customParams', namespaces)\n",
    "        if custom_parms is not None:\n",
    "            expire_date = custom_parms.find('match_date', namespaces)\n",
    "            if expire_date is not None:\n",
    "                expire_date_text = expire_date.text.strip()\n",
    "                # Define the format of the input date string\n",
    "                input_format = \"%B %d, %Y %H:%M\"\n",
    "\n",
    "                # Parse the date string into a naive datetime object\n",
    "                naive_datetime_obj = datetime.strptime(expire_date_text, input_format)\n",
    "\n",
    "                # Assume the input datetime is in a specific timezone (e.g., 'US/Eastern')\n",
    "                # Replace 'US/Eastern' with the desired timezone\n",
    "                timezone_obj = pytz.timezone('US/Eastern')\n",
    "\n",
    "                # Localize the naive datetime object to the specific timezone\n",
    "                localized_datetime_obj = timezone_obj.localize(naive_datetime_obj)\n",
    "\n",
    "                # Define the output format\n",
    "                output_format = \"%Y-%m-%d %H:%M:%S %Z\"\n",
    "\n",
    "                # Convert the localized datetime object to the desired format\n",
    "                formatted_date = localized_datetime_obj.strftime(output_format)\n",
    "\n",
    "                # print(formatted_date)\n",
    "\n",
    "        if media_group is not None:\n",
    "            teams = media_group.find('media:team', namespaces)\n",
    "            video_content = media_group.find('media:content[@type=\"video/mp4\"]', namespaces)\n",
    "            if teams is not None and video_content is not None:\n",
    "                teams_text = teams.text.strip()\n",
    "                video_url = video_content.get('url')\n",
    "                # Append the team and video URL to the array\n",
    "                teams_videos.append({'teams': teams_text, 'video_url': video_url})\n",
    "\n",
    "    # Print the array\n",
    "    print(teams_videos)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_layout():\n",
    "    # Loop through each item in teams_videos and upload the video\n",
    "    for item in teams_videos:\n",
    "        try:\n",
    "            teams_text = item['teams'].replace(' ', '_')\n",
    "            video_url = item['video_url']\n",
    "\n",
    "            # Step 1: Download the video file from the provided URL\n",
    "            filename = f\"{video_url.split('/')[-1].split('.')[0]}.mp4\"\n",
    "            download_file(video_url, filename)\n",
    "\n",
    "            # Step 2: Upload the video file via POST request\n",
    "            file_path = Path(filename)\n",
    "            data = {\n",
    "                'name': filename,\n",
    "                'folderId': '5',\n",
    "                'deleteOnExpiry': 1,\n",
    "                # 'expires' : '2024-09-08 21:20:00'\n",
    "                'expires': formatted_date\n",
    "            }\n",
    "            headers = {\n",
    "                'Authorization': f'Bearer {access_token}'\n",
    "            }\n",
    "\n",
    "            # Perform the upload\n",
    "            upload_response = upload_file(file_path, upload_url, data, headers)\n",
    "            uploaded_media_id = upload_response.json()['files'][0]['mediaId']\n",
    "            print(f\"Uploaded {filename}: {upload_response.text}\")\n",
    "\n",
    "            # Step 3: Create a new layout for the video\n",
    "            layout_data = {\n",
    "                'resolutionId': 1,\n",
    "                'name': teams_text,\n",
    "                'folderId': '7'\n",
    "            }\n",
    "            layout_headers = {\n",
    "                'Authorization': f'Bearer {access_token}',\n",
    "                'Content-Type': 'application/json'\n",
    "            }\n",
    "            layout_response = requests.post(layout_url, json=layout_data, headers=layout_headers)\n",
    "            layout_response.raise_for_status()\n",
    "            original_layout_id = layout_response.json()['layoutId']\n",
    "            print(f\"Created layout for {teams_text}: {layout_response.text}\")\n",
    "\n",
    "            # Get the draft layout ID\n",
    "            draftid_url = f\"https://cdn2.barvanna.com/api/layout?parentId={original_layout_id}\"\n",
    "            draft_response = requests.get(draftid_url, headers=layout_headers)\n",
    "            draft_response.raise_for_status()\n",
    "            draft_layout_id = draft_response.json()[0]['layoutId']\n",
    "            print(f\"Draft layout ID: {draft_layout_id}\")\n",
    "\n",
    "            # Get the playlist ID of the draft layout\n",
    "            draft_layout_details_url = f\"https://cdn2.barvanna.com/api/layout?layoutId={draft_layout_id}&embed=regions,playlists,widgets\"\n",
    "            draft_layout_response = requests.get(draft_layout_details_url, headers=layout_headers)\n",
    "            draft_layout_response.raise_for_status()\n",
    "            playlist_id = draft_layout_response.json()[0]['regions'][0]['regionPlaylist']['playlistId']\n",
    "            print(f\"Playlist ID: {playlist_id}\")\n",
    "\n",
    "            # Step 4: Assign the uploaded media to the playlist\n",
    "            assign_url = f'https://cdn2.barvanna.com/api/playlist/library/assign/{playlist_id}'\n",
    "            payload = {'media': [uploaded_media_id]}  # Ensure the media is sent as an array\n",
    "            assign_response = requests.post(assign_url, json=payload, headers=layout_headers)\n",
    "            assign_response.raise_for_status()\n",
    "            print(f\"Assigned media ID {uploaded_media_id} to playlist ID {playlist_id}\")\n",
    "\n",
    "            # Step 5: Publish the layout\n",
    "            publish_url = f'https://cdn2.barvanna.com/api/layout/publish/{original_layout_id}'\n",
    "            publishref = {'publishNow': 1}\n",
    "            publish_response = requests.put(publish_url, json=publishref, headers=layout_headers)\n",
    "            publish_response.raise_for_status()\n",
    "            published_layout_id = publish_response.json()['layoutId']\n",
    "            print(f\"Published layout ID: {published_layout_id}\")\n",
    "\n",
    "            # Step 6: Insert the published layout into the campaign\n",
    "            # campaign_url = 'https://cdn2.barvanna.com/api/campaign/layout/assign/2248'\n",
    "            # campaign_payload = {'layoutId': published_layout_id}\n",
    "            # campaign_response = requests.post(campaign_url, json=campaign_payload, headers=layout_headers)\n",
    "            # campaign_response.raise_for_status()\n",
    "            # print(f\"Inserted layout ID {published_layout_id} into campaign\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {item}: {e}\")\n",
    "\n",
    "    print(\"Completed processing all items\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response met the expected criteria of 15 layout in the folder\n"
     ]
    }
   ],
   "source": [
    "#check if the MLB folder is empty and dont have 15 matches , now grab the matches and create the layout one by one if the result dont have 15 matches\n",
    "\n",
    "if not result:\n",
    "    # Code to execute if result is False\n",
    "    print(\"The response did not meet the expected criteria. Executing code to download and setup all 15 layout\")\n",
    "    # Insert your alternate block of code here\n",
    "    fetch_source()\n",
    "    create_layout()   \n",
    "    \n",
    "else:\n",
    "    print(\"The response met the expected criteria of 15 layout in the folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_names = teams_videos\n",
    "cms_layout = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'layout': 'CUBS_,_ROYALS', 'layoutId': 11261}, {'layout': 'DODGERS_,_ASTROS', 'layoutId': 11259}, {'layout': 'GUARDIANS_,_PHILLIES', 'layoutId': 11275}, {'layout': 'MARINERS_,_WHITE_SOX', 'layoutId': 11265}, {'layout': 'MARLINS_,_BREWERS', 'layoutId': 11255}, {'layout': 'NATIONALS_,_CARDINALS', 'layoutId': 11257}, {'layout': 'PADRES_,_ORIOLES', 'layoutId': 11279}, {'layout': 'PIRATES_,_DIAMONDBACKS', 'layoutId': 11285}, {'layout': 'RANGERS_,_BLUE_JAYS', 'layoutId': 11271}, {'layout': 'REDS_,_RAYS', 'layoutId': 11277}, {'layout': 'ROCKIES_,_GIANTS', 'layoutId': 11253}, {'layout': 'test rename', 'layoutId': 11314}, {'layout': 'test rename test', 'layoutId': 11316}, {'layout': 'TWINS_,_TIGERS', 'layoutId': 11273}, {'layout': 'YANKEES_,_RED_SOX', 'layoutId': 11263}]\n"
     ]
    }
   ],
   "source": [
    "#now check and compare the layout name and source names.\n",
    "#lets fetch source and fetch layout name from the cms folder and make an array and compare the both names respectively.\n",
    "#the araay comparison may be up and down , but what we do is , we dont touch existing names and we replace new name from source to unmatch layout in cms.\n",
    "\n",
    "def fetch_and_merge_layouts(url1, url2, headers):\n",
    "    \"\"\"\n",
    "    Fetch JSON data from two URLs with headers, merge them, and extract 'layout' names and 'layoutId's into an array.\n",
    "    \n",
    "    Parameters:\n",
    "    url1 (str): The first URL to fetch JSON data from.\n",
    "    url2 (str): The second URL to fetch JSON data from.\n",
    "    headers (dict): Headers to include in the HTTP requests.\n",
    "    \n",
    "    Returns:\n",
    "    list: An array of dictionaries containing 'layout' names and 'layoutId's from the merged JSON data.\n",
    "    \"\"\"\n",
    "    # Fetch JSON data from both URLs with headers\n",
    "    response1 = requests.get(url1, headers=headers)\n",
    "    response2 = requests.get(url2, headers=headers)\n",
    "\n",
    "    # Parse the JSON data\n",
    "    json_data1 = response1.json()\n",
    "    json_data2 = response2.json()\n",
    "\n",
    "    # Merge the two JSON arrays\n",
    "    merged_data = json_data1 + json_data2\n",
    "\n",
    "    # Extract 'layout' names and 'layoutId's into a list of dictionaries\n",
    "    layout_details = [{'layout': item['layout'], 'layoutId': item.get('layoutId')} for item in merged_data]\n",
    "\n",
    "    return layout_details\n",
    "\n",
    "# Example usage\n",
    "url1 = 'https://cdn2.barvanna.com/api/layout?folderId=7&start=0&size=10'\n",
    "url2 = 'https://cdn2.barvanna.com/api/layout?folderId=7&start=10&size=15'\n",
    "\n",
    "# Assuming headers is already defined in your environment\n",
    "cms_layout = fetch_and_merge_layouts(url1, url2, headers)\n",
    "print(cms_layout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'teams': 'PIRATES , DIAMONDBACKS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/07/1a/25/7d/071a257dc936ad2b0fd7cdaa68ebc718.preview.mp4'}, {'teams': 'ROCKIES , GIANTS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/c7/c0/fd/88/c7c0fd884b50bf029d0ac194345f20da.preview.mp4'}, {'teams': 'MARLINS , BREWERS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/7a/95/a6/68/7a95a668e667126b19f1e1d6d6e243dd.preview.mp4'}, {'teams': 'NATIONALS , CARDINALS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/a3/53/6d/61/a3536d614e090ea5481fdb80ebd505c9.preview.mp4'}, {'teams': 'DODGERS , ASTROS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/d4/33/8a/5b/d4338a5b2996cdba02128f493662709d.preview.mp4'}, {'teams': 'CUBS , ROYALS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/8f/d1/ed/71/8fd1ed71dbc5b5a9788684c75b29fa3d.preview.mp4'}, {'teams': 'YANKEES , RED SOX', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/f1/0e/e4/93/f10ee493dcaf6eee96f3503286f094c4.preview.mp4'}, {'teams': 'MARINERS , WHITE SOX', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/3f/6f/fd/18/3f6ffd18d02907f0bbe2f105040bcf6d.preview.mp4'}, {'teams': 'BRAVES , METS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/2c/c5/e4/89/2cc5e4893630ff7805d88b0770875c2c.preview.mp4'}, {'teams': 'ATHLETICS , ANGELS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/bc/97/a6/79/bc97a679ae98e4b73a9653b3a88619eb.preview.mp4'}, {'teams': 'RANGERS , BLUE JAYS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/d7/fb/6a/ac/d7fb6aac046f5bf792a8569f1224635d.preview.mp4'}, {'teams': 'TWINS , TIGERS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/6d/f8/f0/50/6df8f05038f35abad2e9994a0e466ea1.preview.mp4'}, {'teams': 'GUARDIANS , PHILLIES', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/b7/4a/93/36/b74a933667e008d26c79471ca76bf9f7.preview.mp4'}, {'teams': 'REDS , RAYS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/da/43/da/9e/da43da9ec08f293b2e090f4a093f3b2a.preview.mp4'}, {'teams': 'PADRES , ORIOLES', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/19/e9/e5/84/19e9e58452df5ed0d469afa5ae02c7fc.preview.mp4'}]\n",
      "[{'replace_layout': 'test rename', 'layout_id': 11314, 'by_team': 'BRAVES , METS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/2c/c5/e4/89/2cc5e4893630ff7805d88b0770875c2c.preview.mp4'}, {'replace_layout': 'test rename test', 'layout_id': 11316, 'by_team': 'ATHLETICS , ANGELS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/bc/97/a6/79/bc97a679ae98e4b73a9653b3a88619eb.preview.mp4'}]\n"
     ]
    }
   ],
   "source": [
    "fetch_source()\n",
    "missing_layouts = []\n",
    "missing_teams = []\n",
    "\n",
    "def compare_arrays(source, cms):\n",
    "    \"\"\"\n",
    "    Compares source and cms arrays, returning two lists:\n",
    "        1. Missing layouts (present in cms but not in source), with layout ID.\n",
    "        2. Missing teams (present in source but not in cms), with team name and video URL.\n",
    "    \"\"\"\n",
    "    source_dict = {tuple(item['teams'].split(' , ')): item for item in source}\n",
    "    cms_dict = {tuple(item['layout'].replace('_', ' ').split(' , ')): item for item in cms}\n",
    "\n",
    "   \n",
    "    for layout, item in cms_dict.items():\n",
    "        if layout not in source_dict:\n",
    "            missing_layouts.append({'layout': item['layout'], 'layoutId': item['layoutId']})\n",
    "\n",
    "    \n",
    "    for team, item in source_dict.items():\n",
    "        if team not in cms_dict:\n",
    "            missing_teams.append({'teams': item['teams'], 'video_url': item['video_url']})\n",
    "\n",
    "# Find the missing layouts\n",
    "update_result = compare_arrays(source_names, cms_layout)\n",
    "\n",
    "def create_replacement_array(missing_layouts, missing_teams):\n",
    "    \"\"\"Creates a replacement array based on missing layouts and teams.\"\"\"\n",
    "    replacements = []\n",
    "    max_length = max(len(missing_layouts), len(missing_teams))\n",
    "\n",
    "    for i in range(max_length):\n",
    "        layout_data = missing_layouts[i] if i < len(missing_layouts) else {'layout': None, 'layoutId': None}\n",
    "        team_data = missing_teams[i] if i < len(missing_teams) else {'teams': None, 'video_url': None}\n",
    "        \n",
    "        # Only create a replacement if either layout or team data is not None\n",
    "        if layout_data['layout'] or team_data['teams']:\n",
    "            replacements.append({\n",
    "                'replace_layout': layout_data['layout'],\n",
    "                'layout_id': layout_data['layoutId'],\n",
    "                'by_team': team_data['teams'],\n",
    "                'video_url': team_data['video_url']\n",
    "            })\n",
    "\n",
    "    return replacements\n",
    "\n",
    "\n",
    "\n",
    "replacement_array = create_replacement_array(missing_layouts, missing_teams)\n",
    "print(replacement_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2cc5e4893630ff7805d88b0770875c2c.mp4: 100%|██████████| 133M/133M [00:45<00:00, 2.91MiB/s]   \n",
      "Uploading 2cc5e4893630ff7805d88b0770875c2c.mp4: 100%|██████████| 133M/133M [02:49<00:00, 785kiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing {'replace_layout': 'test rename', 'layout_id': 11314, 'by_team': 'BRAVES , METS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/2c/c5/e4/89/2cc5e4893630ff7805d88b0770875c2c.preview.mp4'}: 'mediaId'\n",
      "<Response [200]>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bc97a679ae98e4b73a9653b3a88619eb.mp4:  26%|██▌       | 34.7M/134M [00:30<01:25, 1.15MiB/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 105\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError processing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted processing all items\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 105\u001b[0m delete_and_create_new_layout(replacement_array)\n",
      "Cell \u001b[0;32mIn[49], line 28\u001b[0m, in \u001b[0;36mdelete_and_create_new_layout\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Step 1: Download the video file from the provided URL\u001b[39;00m\n\u001b[1;32m     27\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvideo_url\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 28\u001b[0m download_file(video_url, filename)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Step 2: Upload the video file via POST request\u001b[39;00m\n\u001b[1;32m     31\u001b[0m file_path \u001b[38;5;241m=\u001b[39m Path(filename)\n",
      "Cell \u001b[0;32mIn[41], line 19\u001b[0m, in \u001b[0;36mdownload_file\u001b[0;34m(url, local_filename)\u001b[0m\n\u001b[1;32m     12\u001b[0m total_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(r\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent-length\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(local_filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f, tqdm(\n\u001b[1;32m     14\u001b[0m     desc\u001b[38;5;241m=\u001b[39mlocal_filename,\n\u001b[1;32m     15\u001b[0m     total\u001b[38;5;241m=\u001b[39mtotal_size,\n\u001b[1;32m     16\u001b[0m     unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miB\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     17\u001b[0m     unit_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     18\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m bar:\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m r\u001b[38;5;241m.\u001b[39miter_content(chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8192\u001b[39m):\n\u001b[1;32m     20\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(chunk)\n\u001b[1;32m     21\u001b[0m         bar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(chunk))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/requests/models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/urllib3/response.py:936\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    935\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 936\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(amt\u001b[38;5;241m=\u001b[39mamt, decode_content\u001b[38;5;241m=\u001b[39mdecode_content)\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m    939\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/urllib3/response.py:879\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    876\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m amt:\n\u001b[1;32m    877\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer\u001b[38;5;241m.\u001b[39mget(amt)\n\u001b[0;32m--> 879\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raw_read(amt)\n\u001b[1;32m    881\u001b[0m flush_decoder \u001b[38;5;241m=\u001b[39m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/urllib3/response.py:814\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    811\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 814\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp_read(amt) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[1;32m    817\u001b[0m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[1;32m    824\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/urllib3/response.py:799\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m buffer\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m    797\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    798\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 799\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/http/client.py:473\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    472\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 473\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread(amt)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/ssl.py:1315\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1312\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1313\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1314\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/ssl.py:1167\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1168\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#create a function to delete the layout that is in the cms using update_result\n",
    "\n",
    "def delete_and_create_new_layout(arr):\n",
    "    # Loop through each item in teams_videos and upload the video\n",
    "    for item in arr:\n",
    "        try:\n",
    "            layout_headers = {\n",
    "                'Authorization': f'Bearer {access_token}',\n",
    "                'Content-Type': 'application/json'\n",
    "            }\n",
    "\n",
    "            teams_text = item['by_team'].replace(' ', '_')\n",
    "            video_url = item['video_url']\n",
    "            layoutid = 0\n",
    "             \n",
    "            #editing the layout name \n",
    "            if item['layout_id'] is not None:\n",
    "               layoutid = item['layout_id']\n",
    "               edit_url = f\"https://cdn2.barvanna.com/api/layout/{layoutid}\"\n",
    "                # Define the data payload with the parameters you want to update\n",
    "               data_payload = {\n",
    "                        \"name\": teams_text  # Assuming 'name' is part of the item dictionary\n",
    "                    }\n",
    "               edit_response = requests.put(edit_url, headers=layout_headers , json=data_payload)\n",
    "               print(edit_response)\n",
    "\n",
    "            # Step 1: Download the video file from the provided URL\n",
    "            filename = f\"{video_url.split('/')[-1].split('.')[0]}.mp4\"\n",
    "            download_file(video_url, filename)\n",
    "\n",
    "            # Step 2: Upload the video file via POST request\n",
    "            file_path = Path(filename)\n",
    "            data = {\n",
    "                'name': filename,\n",
    "                'folderId': '5',\n",
    "                'deleteOnExpiry': 1,\n",
    "                # 'expires' : '2024-09-08 21:20:00'\n",
    "                'expires': formatted_date\n",
    "            }\n",
    "            headers = {\n",
    "                'Authorization': f'Bearer {access_token}'\n",
    "            }\n",
    "\n",
    "            # Perform the upload\n",
    "            upload_response = upload_file(file_path, upload_url, data, headers)\n",
    "            uploaded_media_id = upload_response.json()['files'][0]['mediaId']\n",
    "            print(f\"Uploaded {filename}: {upload_response.text}\")\n",
    "\n",
    "            #do checkout and get draft id\n",
    "            # # Get the draft layout ID\n",
    "            draftid_url = f\"https://cdn2.barvanna.com/api/layout/checkout/{layoutid}\"\n",
    "            layoutid_payload = {\n",
    "                    \"layoutId\": layoutid,\n",
    "                }\n",
    "            draft_response = requests.put(draftid_url, headers=layout_headers , json=layoutid_payload)\n",
    "            draft_response.raise_for_status()\n",
    "            draft_layout_id = draft_response.json()['layoutId']\n",
    "            print(f\"Draft layout ID: {draft_layout_id}\")\n",
    "\n",
    "            #now get the playlist name , delete the existing video and put another one , ok !\n",
    "            # Get the playlist ID of the draft layout\n",
    "            draft_layout_details_url = f\"https://cdn2.barvanna.com/api/layout?layoutId={draft_layout_id}&embed=regions,playlists,widgets\"\n",
    "            draft_layout_response = requests.get(draft_layout_details_url, headers=layout_headers)\n",
    "            draft_layout_response.raise_for_status()\n",
    "            print(draft_layout_response.json())\n",
    "            playlist_id = draft_layout_response.json()[0]['regions'][0]['regionPlaylist']['playlistId']\n",
    "            print(f\"Playlist ID: {playlist_id}\")\n",
    "\n",
    "            #get old widget id (old video) and delete it from playlist\n",
    "            old_video_widget_id = draft_layout_response.json()[0]['regions'][0]['regionPlaylist']['widgets'][0]['widgetId']\n",
    "            #delete a widget\n",
    "            delete_widget_url = f'https://cdn2.barvanna.com/api/playlist/widget/{old_video_widget_id}'\n",
    "            delete_widget_response = requests.delete(delete_widget_url , headers=layout_headers)\n",
    "            delete_widget_response.raise_for_status()\n",
    "            print(f\"widget deleted :  {old_video_widget_id}\")\n",
    "\n",
    "\n",
    "            # Step 4: Assign the uploaded media to the playlist\n",
    "            assign_url = f'https://cdn2.barvanna.com/api/playlist/library/assign/{playlist_id}'\n",
    "            payload = {'media': [uploaded_media_id]}  # Ensure the media is sent as an array\n",
    "            assign_response = requests.post(assign_url, json=payload, headers=layout_headers)\n",
    "            assign_response.raise_for_status()\n",
    "            print(f\"Assigned media ID 4761 to playlist ID {playlist_id}\")\n",
    "\n",
    "            # Step 5: Publish the layout\n",
    "            publish_url = f'https://cdn2.barvanna.com/api/layout/publish/{layoutid}'\n",
    "            publishref = {'publishNow': 1}\n",
    "            publish_response = requests.put(publish_url, json=publishref, headers=layout_headers)\n",
    "            publish_response.raise_for_status()\n",
    "            published_layout_id = publish_response.json()['layoutId']\n",
    "            print(f\"Published layout ID: {published_layout_id}\")\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {item}: {e}\")\n",
    "\n",
    "    print(\"Completed processing all items\")\n",
    "\n",
    "delete_and_create_new_layout(replacement_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File output_array.json already exists. No data was saved.\n",
      "Loaded Data: [{'teams': 'PIRATES , DIAMONDBACKS', 'video_url': 'https://cdn.itsoch.com/test1.mp4'}, {'teams': 'ROCKIES , GIANTS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/c7/c0/fd/88/c7c0fd884b50bf029d0ac194345f20da.preview.mp4'}, {'teams': 'MARLINS , BREWERS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/7a/95/a6/68/7a95a668e667126b19f1e1d6d6e243dd.preview.mp4'}, {'teams': 'NATIONALS , CARDINALS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/a3/53/6d/61/a3536d614e090ea5481fdb80ebd505c9.preview.mp4'}, {'teams': 'DODGERS , ASTROS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/d4/33/8a/5b/d4338a5b2996cdba02128f493662709d.preview.mp4'}, {'teams': 'CUBS , ROYALS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/8f/d1/ed/71/8fd1ed71dbc5b5a9788684c75b29fa3d.preview.mp4'}, {'teams': 'YANKEES , RED SOX', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/f1/0e/e4/93/f10ee493dcaf6eee96f3503286f094c4.preview.mp4'}, {'teams': 'MARINERS , WHITE SOX', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/3f/6f/fd/18/3f6ffd18d02907f0bbe2f105040bcf6d.preview.mp4'}, {'teams': 'BRAVES , METS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/2c/c5/e4/89/2cc5e4893630ff7805d88b0770875c2c.preview.mp4'}, {'teams': 'ATHLETICS , ANGELS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/bc/97/a6/79/bc97a679ae98e4b73a9653b3a88619eb.preview.mp4'}, {'teams': 'RANGERS , BLUE JAYS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/d7/fb/6a/ac/d7fb6aac046f5bf792a8569f1224635d.preview.mp4'}, {'teams': 'TWINS , TIGERS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/6d/f8/f0/50/6df8f05038f35abad2e9994a0e466ea1.preview.mp4'}, {'teams': 'GUARDIANS , PHILLIES', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/b7/4a/93/36/b74a933667e008d26c79471ca76bf9f7.preview.mp4'}, {'teams': 'REDS , RAYS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/da/43/da/9e/da43da9ec08f293b2e090f4a093f3b2a.preview.mp4'}, {'teams': 'PADRES , ORIOLES', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/19/e9/e5/84/19e9e58452df5ed0d469afa5ae02c7fc.preview.mp4'}]\n",
      "cms layout [{'layout': 'ATHLETICS_,_ANGELS', 'layoutId': 11269}, {'layout': 'BRAVES_,_METS', 'layoutId': 11267}, {'layout': 'CUBS_,_ROYALS', 'layoutId': 11261}, {'layout': 'DODGERS_,_ASTROS', 'layoutId': 11259}, {'layout': 'GUARDIANS_,_PHILLIES', 'layoutId': 11275}, {'layout': 'MARINERS_,_WHITE_SOX', 'layoutId': 11265}, {'layout': 'MARLINS_,_BREWERS', 'layoutId': 11255}, {'layout': 'NATIONALS_,_CARDINALS', 'layoutId': 11257}, {'layout': 'PADRES_,_ORIOLES', 'layoutId': 11279}, {'layout': 'PIRATES_,_DIAMONDBACKS', 'layoutId': 11283}, {'layout': 'RANGERS_,_BLUE_JAYS', 'layoutId': 11271}, {'layout': 'REDS_,_RAYS', 'layoutId': 11277}, {'layout': 'ROCKIES_,_GIANTS', 'layoutId': 11253}, {'layout': 'TWINS_,_TIGERS', 'layoutId': 11273}, {'layout': 'YANKEES_,_RED_SOX', 'layoutId': 11263}]\n",
      "[{'teams': 'PIRATES , DIAMONDBACKS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/07/1a/25/7d/071a257dc936ad2b0fd7cdaa68ebc718.preview.mp4'}]\n",
      "There is a new video in the existing layout, updating the layout.\n",
      "new data :  [{'layout_id': 11283, 'by_team': 'PIRATES , DIAMONDBACKS', 'video_url': 'https://assets.vedia.ai/rawshorts/preview/videos/07/1a/25/7d/071a257dc936ad2b0fd7cdaa68ebc718.preview.mp4'}]\n",
      "<Response [204]>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "071a257dc936ad2b0fd7cdaa68ebc718.mp4: 100%|██████████| 133M/133M [00:13<00:00, 10.1MiB/s]   \n",
      "Uploading 071a257dc936ad2b0fd7cdaa68ebc718.mp4: 100%|██████████| 133M/133M [01:35<00:00, 1.39MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 071a257dc936ad2b0fd7cdaa68ebc718.mp4: {\"files\":[{\"name\":\"071a257dc936ad2b0fd7cdaa68ebc718.mp4\",\"size\":133280895,\"type\":\"video\\/mp4\",\"url\":\"\\/api\\/library?file=071a257dc936ad2b0fd7cdaa68ebc718.mp4&download=1\",\"width\":null,\"height\":null,\"mediaId\":4761,\"storedas\":\"4761.mp4\",\"duration\":73,\"retired\":0,\"fileSize\":133280895,\"md5\":\"071a257dc936ad2b0fd7cdaa68ebc718\",\"enableStat\":\"Inherit\",\"mediaType\":\"video\",\"fileName\":\"071a257dc936ad2b0fd7cdaa68ebc718.mp4\",\"delete_url\":\"\\/api\\/library?file=071a257dc936ad2b0fd7cdaa68ebc718.mp4\",\"delete_type\":\"DELETE\"}]}\n",
      "Created layout for PIRATES_,_DIAMONDBACKS: {\"layoutId\":11284,\"ownerId\":5,\"campaignId\":2467,\"parentId\":null,\"publishedStatusId\":2,\"publishedStatus\":\"Draft\",\"publishedDate\":null,\"backgroundImageId\":null,\"schemaVersion\":null,\"layout\":\"PIRATES_,_DIAMONDBACKS\",\"description\":null,\"backgroundColor\":\"#000\",\"createdDt\":null,\"modifiedDt\":null,\"status\":3,\"retired\":null,\"backgroundzIndex\":0,\"width\":1920,\"height\":1080,\"orientation\":\"landscape\",\"displayOrder\":1,\"duration\":null,\"statusMessage\":null,\"enableStat\":0,\"autoApplyTransitions\":0,\"code\":null,\"regions\":[{\"regionId\":21674,\"layoutId\":11284,\"ownerId\":5,\"name\":\"PIRATES_,_DIAMONDBACKS-0\",\"width\":1920,\"height\":1080,\"top\":0,\"left\":0,\"zIndex\":0,\"regionOptions\":[],\"permissions\":[],\"duration\":0,\"isDrawer\":0,\"actions\":[],\"tempId\":null,\"regionPlaylist\":{\"playlistId\":21678,\"ownerId\":5,\"name\":\"PIRATES_,_DIAMONDBACKS-0\",\"regionId\":21674,\"isDynamic\":0,\"filterMediaName\":null,\"filterMediaNameLogicalOperator\":\"OR\",\"filterMediaTags\":null,\"filterExactTags\":\"0\",\"filterMediaTagsLogicalOperator\":\"OR\",\"maxNumberOfItems\":0,\"createdDt\":\"2024-08-04 22:51:24\",\"modifiedDt\":\"2024-08-04 22:51:24\",\"duration\":0,\"requiresDurationUpdate\":1,\"enableStat\":null,\"tags\":[],\"widgets\":[],\"permissions\":[],\"tempId\":null,\"owner\":\"devops\",\"groupsWithPermissions\":null,\"folderId\":7,\"permissionsFolderId\":1}}],\"tags\":[],\"drawers\":[],\"actions\":[],\"permissions\":[],\"campaigns\":[],\"owner\":null,\"groupsWithPermissions\":null,\"folderId\":7,\"permissionsFolderId\":null}\n",
      "Draft layout ID: 11285\n",
      "Playlist ID: 21679\n",
      "Assigned media ID 4761 to playlist ID 21679\n",
      "Published layout ID: 11285\n",
      "Inserted layout ID 11285 into campaign\n",
      "Completed processing all items\n",
      "Data saved to output_array.json\n"
     ]
    }
   ],
   "source": [
    "# download the mrss feed into a file\n",
    "# match the old file with new file , only check similar title video name\n",
    "# if video is changed , create a array , put layout id to delete and match name and video name . \n",
    "# if video is changed then delete the old file and save latest mrss as mrss old.\n",
    "\n",
    "#downloading the mrss feed and saving it in the local storage\n",
    "# Define the file path\n",
    "file_path = 'output_array.json'\n",
    "\n",
    "# Save the array to a JSON file\n",
    "# Save the array to a JSON file only if the file doesn't exist\n",
    "if not os.path.exists(file_path):\n",
    "    with open(file_path, 'w') as json_file:\n",
    "        json.dump(teams_videos, json_file, indent=4)\n",
    "    print(f\"Data saved to {file_path}\")\n",
    "else:\n",
    "    print(f\"File {file_path} already exists. No data was saved.\")\n",
    "\n",
    "# Load the array from a JSON file\n",
    "def load_from_json(path):\n",
    "    with open(path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "    return data\n",
    "\n",
    "# Load the array from the file later\n",
    "loaded_data = load_from_json(file_path)\n",
    "print(\"Loaded Data:\", loaded_data)\n",
    "\n",
    "print(\"cms layout\" , cms_layout)\n",
    "\n",
    "# compare loaded data with source data array\n",
    "# Initialize an empty list for new videos\n",
    "new_video = []\n",
    "\n",
    "# Iterate through the output array\n",
    "for out_item in loaded_data:\n",
    "    for src_item in teams_videos:\n",
    "        if out_item['teams'] == src_item['teams'] and out_item['video_url'] != src_item['video_url']:\n",
    "            new_video.append({'teams': out_item['teams'], 'video_url': src_item['video_url']})\n",
    "\n",
    "print (new_video)\n",
    "new_update_array = []\n",
    "\n",
    "\n",
    "# Check if new_video is empty or not and print the appropriate message\n",
    "if not new_video:\n",
    "    print(\"No changes.\")\n",
    "else:\n",
    "    print(\"There is a new video in the existing layout, updating the layout.\")\n",
    "    # compare new video with cms layout and delete the cms layout and replace by new video and name\n",
    "    # Initialize the new array\n",
    "\n",
    "    # Iterate over the new update array\n",
    "    for update in new_video:\n",
    "        teams = update['teams'].replace(' ', '_')  # Format to match layout in CMS\n",
    "        for item in cms_layout:\n",
    "            if item['layout'] == teams:\n",
    "                new_entry = {\n",
    "                    'layout_id': item['layoutId'],\n",
    "                    'by_team': update['teams'],\n",
    "                    'video_url': update['video_url']\n",
    "                }\n",
    "                new_update_array.append(new_entry)\n",
    "    \n",
    "    print(\"new data : \" , new_update_array)\n",
    "     #delete layout id , and put new layout (replacing the layout simplified)\n",
    "    delete_and_create_new_layout(new_update_array)\n",
    "    #delete existing output_array and replace it with current source\n",
    "    # Save the array to a JSON file, replacing it if it already exists\n",
    "    with open(file_path, 'w') as json_file:\n",
    "        json.dump(teams_videos, json_file, indent=4)\n",
    "        print(f\"Data saved to {file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
